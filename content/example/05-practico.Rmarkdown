---
title: "Análisis Factorial Exploratorio I"
linktitle: "5: Análisis Factorial Exploratorio I"
date: "2023-04-09"
menu:
  example:
    parent: Ejemplos
    weight: 5
type: docs
toc: true
editor_options: 
  chunk_output_type: console
---

```{r set up, echo = F}
knitr::opts_knit$set(sql.max.print = 10)
```

## 0. Objetivo del práctico

El objetivo de este práctico es revisar como realizar la comprobación de supuestos y tratamiento de variables para la realización de un Análisis factorial Exploratorio. 


## 1. Carga y gestión de datos

En primer lugar, cargaremos una base de datos de PNUD 2015, que incluye los siguientes ítem. Con estos esperamos revisar si existen estructuras latentes en como las personas evalúan las oportunidades que entrega Chile. 

![](https://raw.githubusercontent.com/Clases-GabrielSotomayor/pruebapagina/master/static/slides/img/05/Practico.png)

Estos datos están en formato csv (comma separated value), por lo cual podemos leerlos con la función *read.csv2* incluida con r base.

```{r}
#cargamos los datos 
datos <- read.csv2("https://raw.githubusercontent.com/Clases-GabrielSotomayor/pruebapagina/master/static/slides/data/EjemploAF.csv")
```


A continuación, revisamos los datos y daremos por perdidos los valores no sabe y no responde. 

```{r}
#   3.    DEFINIR VALORES PERDIDOS para Las variables, intervalares discretas de 7 categorias de las base de Datos PNUD 2015
summary(datos)

#Categorizar como NA 8 y 9 (NS/NR).
datos[datos==9] <- NA
datos[datos==8] <- NA
summary(datos)
```

A continuación, exploramos los datos para conocer sus medias y distribución. En este punto es relevante revisar si existe mucha diferencia en sus niveles de variabilidad, ya que esto afectara los resultados del Análisis Factorial Exploratorio.

```{r}
#   4.    ANALISIS DESCRIPTIVO DE LAS VARIABLES. 

#         Podemos solicitar los descriptivos variable por variable.
summary(datos$SALUD)
summary(datos$INGR)

#         Con este comando se solicitan resultados descriptivos para las 9 variables al mismo tiempo. 

summary(datos)
```

##  2.  Comprobación de supuestos

En este bloque de código, se cargan las bibliotecas necesarias para realizar la comprobación de supuestos.

```{r,warning= F}
library(psych)
library(MVN)
```

Para la comprobación de supuestos partiremos por generar una base de datos listwise, es decir, en la que se eliminan todos los casos que tienen valores perdidos en alguno de los ítem. Esto es posible en este caso por el bajo número de perdidos existentes. 

```{r}
#   5a.   Crear una base solo con listwise (para test de Mardia)

datosLW <- na.omit(datos)
summary(datosLW)
dim(datosLW)
```

A continuación, revisaremos la existencia de casos atípicos multivariantes a partir del cálculo y evaluación de la distancia de Mahalanobis. 

```{r}
#Tratamiento de casos atipicos

mean<-colMeans(datosLW[1:9])
mean
Sx<-cov(datosLW[1:9]) #matriz de varianza covariaza 
Sx
D2<-mahalanobis(datosLW[1:9],mean,Sx)

datosLW$sigmahala=(1-pchisq(D2, 3))  

datosLW<-datosLW[which(datosLW$sigmahala>0.01),]#dar por perdido o eliminar caso atipico
datosLW$sigmahala<-NULL
```

A continuación, utilizamos el test de Mardia para evaluar la existencia de normalidad multivariante en nuestros datos.  

```{r}
  #Test de Mardia.
MVN::mvn(datosLW,mvnTest	= "mardia",multivariatePlot="qq")

```

A nivel univariado debemos comprobar que existan niveles moderados de asimetría en nuestra variables de interés. 

```{r}
#   5b.   Observar asimetria

s1<-skew(datosLW$SALUD, type=2, na.rm=T)
s2<-skew(datosLW$INGR, type=2, na.rm=T)
s3<-skew(datosLW$TRAB, type=2, na.rm=T)
s4<-skew(datosLW$EDUC, type=2, na.rm=T)
s5<-skew(datosLW$VIVI, type=2, na.rm=T)
s6<-skew(datosLW$SEGUR, type=2, na.rm=T)
s7<-skew(datosLW$MEDIO, type=2, na.rm=T)
s8<-skew(datosLW$LIBER, type=2, na.rm=T)
s9<-skew(datosLW$PROYE, type=2, na.rm=T)
```

El test KS nos permite evaluar la existencia de normalidad en cada una de las variables. 

```{r}
#Test de KS

ks.test(datosLW$SALUD, "pnorm", mean(datosLW$SALUD, na.rm=T), sd(datosLW$SALUD,na.rm=T))
# ks.test(datosLW$INGR, "pnorm", mean(datosLW$INGR, na.rm=T), sd(datosLW$INGR,na.rm=T))
# ks.test(datosLW$TRAB, "pnorm", mean(datosLW$TRAB, na.rm=T), sd(datosLW$TRAB,na.rm=T))
# ks.test(datosLW$EDUC, "pnorm", mean(datosLW$EDUC, na.rm=T), sd(datosLW$EDUC,na.rm=T))
# ks.test(datosLW$VIVI, "pnorm", mean(datosLW$VIVI, na.rm=T), sd(datosLW$VIVI,na.rm=T))
# ks.test(datosLW$SEGUR, "pnorm", mean(datosLW$SEGUR, na.rm=T), sd(datosLW$SEGUR,na.rm=T))
# ks.test(datosLW$MEDIO, "pnorm", mean(datosLW$MEDIO, na.rm=T), sd(datosLW$MEDIO,na.rm=T))
# ks.test(datosLW$LIBER, "pnorm", mean(datosLW$LIBER, na.rm=T), sd(datosLW$LIBER,na.rm=T))
# ks.test(datosLW$PROYE, "pnorm", mean(datosLW$PROYE, na.rm=T), sd(datosLW$PROYE,na.rm=T))
```

A continuación calculamos la matriz de correlaciones para evaluar la existencia de colinealidad. Esto es relevante porque es necesario que exista suficiente varianza común entre las variables para la extracción de factores comunes. 

```{r}
#Matriz de Correlaciones 
#Uso de Pearson por caracteristicas de las variables (discretas de baja asimetria)

cor_datos<- cor(datosLW)
print(cor_datos)
print(det(cor_datos))#Cercano a 0 correlacion multivariante
```



```{r}
#Probar con matriz policlorica en caso de estar trabajando con variables ordinales.
polychoric(datosLW)
```

Por último, chequeamos la existencia de multicolinealidad.

```{r}
#   5c.   MULTICOLINEALIDAD
#Test de esfericidad de Bartlett. Contrastar la hipotesis Nula de Igualdad con Matriz identidad

print(cortest.bartlett(cor_datos,n = nrow(datosLW)))

#KMO

KMO(datosLW)
```
