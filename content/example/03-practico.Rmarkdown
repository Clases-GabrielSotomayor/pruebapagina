---
title: "3. Análisis de Regresión Lineal Múltiple"
linktitle: "3. Análisis de Regresión Lineal Múltiple"
date: "2023-03-27"
menu:
  example:
    parent: Ejemplos
    weight: 3
type: docs
toc: true
editor_options:
  chunk_output_type: console
---

# 0. Objetivo del práctico

El objetivo de este práctico es presentar una introducción al Análisis de Regresión Lineal Múltiple,visualizar sus resultados y evaluar el ajuste de los modelos y el cumplimiento de los supuestos de la técnica.   

Para esto haremos uso de la encuesta [CASEN (2020)](http://observatorio.ministeriodesarrollosocial.gob.cl/encuesta-casen-en-pandemia-2020), la mayor encuesta de hogares realizada en Chile, a cargo del Ministerio de Desarrollo Social, de carácter transversal y multipropósito, es el principal instrumento de medición socioeconómica para el diseño y evaluación de la política social. Permite conocer periódicamente la situación socioeconómica de los hogares y de la población que reside en viviendas particulares, a través de preguntas referidas a composición familiar, educación, salud, vivienda, trabajo e ingresos, entre otros aspectos. 

## Cargar paquetes a utilizar
Para iniciar se cargan los paquetes necesarios para realizar el análisis de regresión. Al utilizar la función p_load() del paquete "pacman", si alguno de los paquetes no está instalado, se instalará automáticamente con la función install.packages(). Los paquetes utilizados son:

haven: para cargar archivos SPSS en R.
texreg: para crear tablas de resumen de regresión.
corrplot: para visualizar las correlaciones entre variables.
coefplot: para crear gráficos de coeficientes de regresión.
ggplot2: para crear gráficos.
sjPlot: para crear tablas de resumen de regresión y gráficos.
summarytools: para crear resúmenes de variables.
dplyr: para manipulación de datos.
lmtest: para pruebas de diagnóstico de regresión.
sandwich: para estimar errores robustos en regresiones.


```{r}
# Cargar paquetes a utilizar
if (!require("pacman")) install.packages("pacman")
pacman::p_load(haven,texreg,corrplot,coefplot,ggplot2,sjPlot,summarytools,dplyr,
               lmtest,sandwich)
```

## Importar datos 
A continuación se carga la base de datos de CASEN 2020. La base de datos se encuentra en la página web del Observatorio Social. La función read_spss() del paquete haven se utiliza para cargar la base de datos.

Primero, se descarga un archivo comprimido que contiene la base de datos desde la página web utilizando la función download.file(). Luego, se descomprime el archivo utilizando la función unz() y se carga la base de datos utilizando la función read_sav(). Finalmente, se elimina el archivo temporal que se creó durante el proceso de descarga y descompresión utilizando la función unlink() y remove().

```{r}
temp <- tempfile() #Creamos un archivo temporal
download.file("http://observatorio.ministeriodesarrollosocial.gob.cl/storage/docs/casen/2020/Casen_en_Pandemia_2020_revisada202209.sav.zip",temp) #descargamos los datos
base <- haven::read_sav(unz(temp, "Casen_en_Pandemia_2020_revisada202209.sav")) #cargamos los datos
unlink(temp); remove(temp) #eliminamos el archivo temporal
```

## Análisis previos

El análisis de regresón lineal requiere una variable dependiente continua, mientras que las varaibles independientes pueden corresponder a cualquier nivel de medición. Podemos revisar el tipo de datos  de las variables que utilizaremos con la función "class()"
```{r}
class(base$yautcor)
class(base$esc)
class(base$edad)
class(as_factor(base$sexo))
```

Se utiliza la función dfSummary() del paquete summarytools para crear un resumen de las variables yautcor, esc, edad y sexo de la base de datos. El resumen incluye estadísticas descriptivas y de frecuencia.

```{r}

print(dfSummary(base[,c("yautcor","esc","edad","sexo")], headings = FALSE, method = "render"))
```

A continuación realizamos un análisis de correlaciones bivariadas con el fin de revisar si existe una relación lineal entre la varaible dependiente y las variables independientes, además de comprobar que no existan problemas de colinealidad entre estas últimas.

```{r}
#correlaciones
cor(base[,c("yautcor","esc","edad","sexo")], use="complete.obs")
mc<-cor(base[,c("yautcor","esc","edad","sexo")], use="complete.obs")
corrplot(mc, method = 'number', type = 'upper')
```


```{r, warning=FALSE}
g=ggplot(base, aes(x=log(yautcor), y=esc)) +
  geom_point()+ geom_smooth(method=lm, se=FALSE)
g

```

```{r}
modelo1 <- lm(yautcor~ esc,data = base)
summary(modelo1)
```

```{r}
1-var(modelo1$residuals)/
  var(base$yautcor[!is.na(base$esc)&!is.na(base$edad)&!is.na(base$sexo)],na.rm=T)
```

```{r}
modelo2 <- lm(yautcor~ esc+ edad+ as_factor(sexo),data = base)
modelo3 <- lm(yautcor~ esc+ edad+ as_factor(sexo),data = base,weights = expr)

```

```{r,results = 'asis'}
htmlreg(list(modelo1,modelo2,modelo3), custom.coef.names = c("Intercepto","Escolaridad","Edad","Sexo (ref. Hombre)"))

```

```{r}
coefplot(modelo3)+scale_y_discrete(labels=c("Intercepto","Escolaridad","Edad","Sexo","Sexo (ref. Hombre)"))+
  labs(title = "Gráfico de coeficientes",subtitle = "Modelo 3")+ylab("Coeficientes")

```

## Revisión de supuestos 

```{r,results = 'asis'}
#Casos influyentes
n<- nobs(modelo3) #n de observaciones
k<- length(coef(modelo3)) # n de parametros
dcook<- 4/(n-k-1) #punt de corte


final <- broom::augment_columns(modelo3,data = base)
final$id <- as.numeric(row.names(final))
# identify obs with Cook's D above cutoff
ggplot(final, aes(id, .cooksd))+
  geom_bar(stat="identity", position="identity")+
  xlab("Obs. Number")+ylab("Cook's distance")+
  geom_hline(yintercept=dcook)+
  geom_text(aes(label=ifelse((.cooksd>dcook),id,"")),
            vjust=-0.2, hjust=0.5)

ident<- final %>% filter(.cooksd>dcook)
base2<- final %>% filter(!(id %in% ident$id))

modelo4<-lm(yautcor~ esc+ edad+ as_factor(sexo),data = base2,weights = expr)
htmlreg(list(modelo3,modelo4), custom.coef.names = c("Intercepto","Escolaridad","Edad","Sexo (ref. Hombre)"))
```

```{r}
#Linealidad
ggplot(modelo4, aes(.fitted, .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = TRUE)
```

```{r,results = 'asis'}
#homogenidad de varianza
car::ncvTest(modelo4)

model_robust<- coeftest(modelo4, vcov=vcovHC)
htmlreg(list(modelo4,model_robust), custom.coef.names = c("Intercepto","Escolaridad","Edad","Sexo (ref. Hombre)"))
```

```{r}
#multicolinealidad
car::vif(modelo4) #Se espera que no existan valores mayores a 2.5

```

```{r}
#Normalidad de los residuos
hist(modelo4$residuals)

```
